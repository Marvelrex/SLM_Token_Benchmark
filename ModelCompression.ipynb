{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ed6dda0b678747a6a1b33ee3abbc1b98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ec9cdc327eab4ed3b19f3b758d4e2ffb",
              "IPY_MODEL_2e2027e72a99477bada4d7ee7f72f999",
              "IPY_MODEL_1fa9b0b2a7834dc9bf345bc853213890"
            ],
            "layout": "IPY_MODEL_e1cf4593ccee42c498d80580810b57c1"
          }
        },
        "ec9cdc327eab4ed3b19f3b758d4e2ffb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a2bf5253ccf4a44a023453ee92f010a",
            "placeholder": "​",
            "style": "IPY_MODEL_e0c16f471e914e40bc0c65c82dc6700e",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "2e2027e72a99477bada4d7ee7f72f999": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_462f95f703504a6aa8bf49e5c4fc54c4",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e1cf11c9b445493aa6e6b2d782098f02",
            "value": 2
          }
        },
        "1fa9b0b2a7834dc9bf345bc853213890": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ca4b0b6112eb4354bbbd9afb1e32f96c",
            "placeholder": "​",
            "style": "IPY_MODEL_baf838dbddc14c5983a86bff5660f36d",
            "value": " 2/2 [00:04&lt;00:00,  2.00s/it]"
          }
        },
        "e1cf4593ccee42c498d80580810b57c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a2bf5253ccf4a44a023453ee92f010a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0c16f471e914e40bc0c65c82dc6700e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "462f95f703504a6aa8bf49e5c4fc54c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1cf11c9b445493aa6e6b2d782098f02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ca4b0b6112eb4354bbbd9afb1e32f96c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "baf838dbddc14c5983a86bff5660f36d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1fbc2db41ea04e5b95e310366fa495b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_60b862d2f0104ea289bec0e4c53ade21",
              "IPY_MODEL_5b2755b00e1242848b9edff6192a0fde",
              "IPY_MODEL_3560534a24ac489aab2bd53fefacf93d"
            ],
            "layout": "IPY_MODEL_7a194800c02641bd96c73e3e75dfef17"
          }
        },
        "60b862d2f0104ea289bec0e4c53ade21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1a82ca4f62a6496999d54348f7ce4654",
            "placeholder": "​",
            "style": "IPY_MODEL_9ee1956ec95141fe880978d6ae841b9b",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "5b2755b00e1242848b9edff6192a0fde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2b93df45bc474295b5be6cee43d2ba0d",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6b9d7d9a186e452799cbdc32a07174e9",
            "value": 2
          }
        },
        "3560534a24ac489aab2bd53fefacf93d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3d66dcaf6aef4efe8691f9bc47e31cfa",
            "placeholder": "​",
            "style": "IPY_MODEL_3a0a59395c084a7fbfb8bca516e1ddc0",
            "value": " 2/2 [00:03&lt;00:00,  1.83s/it]"
          }
        },
        "7a194800c02641bd96c73e3e75dfef17": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a82ca4f62a6496999d54348f7ce4654": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ee1956ec95141fe880978d6ae841b9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2b93df45bc474295b5be6cee43d2ba0d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b9d7d9a186e452799cbdc32a07174e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3d66dcaf6aef4efe8691f9bc47e31cfa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a0a59395c084a7fbfb8bca516e1ddc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6e16e765f0e64926aac95c9db6e024e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_12d3c50d2b1d49a386ad7e44edd71482",
              "IPY_MODEL_597b33f5fe10483492660aa4f5979f85",
              "IPY_MODEL_ff96549691b847f4b342c4e75fc46735"
            ],
            "layout": "IPY_MODEL_88232c970aaa45c8b94fde572a846c4c"
          }
        },
        "12d3c50d2b1d49a386ad7e44edd71482": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9bf661dda46b443ca51133fd9fa97922",
            "placeholder": "​",
            "style": "IPY_MODEL_a502c2d1e0974c7581a35e9640f36c12",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "597b33f5fe10483492660aa4f5979f85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_19bcea2ac950488a8c16b797b85bc02d",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a7d4fc7c6d4c475a8a393d9c4bda1d62",
            "value": 2
          }
        },
        "ff96549691b847f4b342c4e75fc46735": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_238b0cf8ed90456cb54063195c86e6d8",
            "placeholder": "​",
            "style": "IPY_MODEL_cc24fb6f50ac42149de7574f590a381a",
            "value": " 2/2 [00:02&lt;00:00,  1.01it/s]"
          }
        },
        "88232c970aaa45c8b94fde572a846c4c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9bf661dda46b443ca51133fd9fa97922": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a502c2d1e0974c7581a35e9640f36c12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "19bcea2ac950488a8c16b797b85bc02d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7d4fc7c6d4c475a8a393d9c4bda1d62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "238b0cf8ed90456cb54063195c86e6d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc24fb6f50ac42149de7574f590a381a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "60411189569545cd884e27482fcb89b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e58392abbf2548b4b575e747e95389e2",
              "IPY_MODEL_e67034b0ab9f42949a96c0ddedfaf126",
              "IPY_MODEL_4f313b556af44b49a328ca6c470e011e"
            ],
            "layout": "IPY_MODEL_2adaa3031ce94ec696c5ad717d5ca0cc"
          }
        },
        "e58392abbf2548b4b575e747e95389e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a8dea670aa042c18ec8634f3aadc784",
            "placeholder": "​",
            "style": "IPY_MODEL_a9088a06ad6746e0b5327e17218e3037",
            "value": "CPU pruning @ 40% sparsity: 100%"
          }
        },
        "e67034b0ab9f42949a96c0ddedfaf126": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_368778563a984d3daa2693f0e39594e2",
            "max": 197,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_16506219974c42ddb3cfcb7eaba4276f",
            "value": 197
          }
        },
        "4f313b556af44b49a328ca6c470e011e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_79146d6ce63447c393f9972e03cf3ea9",
            "placeholder": "​",
            "style": "IPY_MODEL_8050ce0c8ce74d639840b503d273f2ee",
            "value": " 197/197 [01:16&lt;00:00,  2.66s/it, layer 197/197 | kept 60.0%]"
          }
        },
        "2adaa3031ce94ec696c5ad717d5ca0cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a8dea670aa042c18ec8634f3aadc784": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9088a06ad6746e0b5327e17218e3037": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "368778563a984d3daa2693f0e39594e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "16506219974c42ddb3cfcb7eaba4276f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "79146d6ce63447c393f9972e03cf3ea9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8050ce0c8ce74d639840b503d273f2ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ba906055b6ed46009fe3041771dc4082": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_538d0737d52f49e080663f5a86c8a51a",
              "IPY_MODEL_ebdde29e7b7d4ea89497dbfd3a21dc9d",
              "IPY_MODEL_a452e602ccc3406aa24bbb765a138b09"
            ],
            "layout": "IPY_MODEL_b0161f94db37448bb88694b2e8184f93"
          }
        },
        "538d0737d52f49e080663f5a86c8a51a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_53bf9b7b6ee74374b5d5384754b1912c",
            "placeholder": "​",
            "style": "IPY_MODEL_d8226b7023b249b18fae08b9d104fb38",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "ebdde29e7b7d4ea89497dbfd3a21dc9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b758e222d54042278fa635070118461d",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d933bd782fd14567a329418f0cad4ba4",
            "value": 2
          }
        },
        "a452e602ccc3406aa24bbb765a138b09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ee8c631cd89549a180f34f5f5062f57a",
            "placeholder": "​",
            "style": "IPY_MODEL_1e26e82fd54343339e1aa9073b7576c4",
            "value": " 2/2 [00:04&lt;00:00,  1.99s/it]"
          }
        },
        "b0161f94db37448bb88694b2e8184f93": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53bf9b7b6ee74374b5d5384754b1912c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8226b7023b249b18fae08b9d104fb38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b758e222d54042278fa635070118461d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d933bd782fd14567a329418f0cad4ba4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ee8c631cd89549a180f34f5f5062f57a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e26e82fd54343339e1aa9073b7576c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fc41030e21c7477ab782be6362198446": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_298522458e7a4990a248ed8bdd1b0c41",
              "IPY_MODEL_84b78169792742d692268084c90fb43b",
              "IPY_MODEL_cb18ecfd1cf04c58addabca7d39f28c4"
            ],
            "layout": "IPY_MODEL_fa4f9685d814419699b42f81c96407bf"
          }
        },
        "298522458e7a4990a248ed8bdd1b0c41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4cc7c681470b4cfdb905e6bb77f90911",
            "placeholder": "​",
            "style": "IPY_MODEL_5a9dfd686c2147eba80876e52bb680c4",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "84b78169792742d692268084c90fb43b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_94e2e9702b044bfaabec0a260a97477f",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_47b7da83d30c45b690548d0d6ede3715",
            "value": 2
          }
        },
        "cb18ecfd1cf04c58addabca7d39f28c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb63ee87d0e34974b427707ea94fc847",
            "placeholder": "​",
            "style": "IPY_MODEL_aaf825e156534d96a108073b6d9b47f0",
            "value": " 2/2 [00:03&lt;00:00,  1.77s/it]"
          }
        },
        "fa4f9685d814419699b42f81c96407bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4cc7c681470b4cfdb905e6bb77f90911": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a9dfd686c2147eba80876e52bb680c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "94e2e9702b044bfaabec0a260a97477f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47b7da83d30c45b690548d0d6ede3715": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "eb63ee87d0e34974b427707ea94fc847": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aaf825e156534d96a108073b6d9b47f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ceb322c9609d4f21b1887976d2984bcc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cc4d447d4db3439f8eb4c0214e22daf2",
              "IPY_MODEL_6a2c27e9191d44bba0e55bff7ae71194",
              "IPY_MODEL_d07f6d79530848f381e4bebee85d9877"
            ],
            "layout": "IPY_MODEL_6e9bdfba1d994ae592c755e0c50ae5e9"
          }
        },
        "cc4d447d4db3439f8eb4c0214e22daf2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_36c923139be14a569782aac549f46ff3",
            "placeholder": "​",
            "style": "IPY_MODEL_dba9289556404d17addeedca243f219f",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "6a2c27e9191d44bba0e55bff7ae71194": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6d858af6fe7048548211a35c186d7681",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_118d9697c88a43c28bfb10c58b1f0508",
            "value": 2
          }
        },
        "d07f6d79530848f381e4bebee85d9877": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ffcc8e2cc5fa4aafa12bb1847ed34bfe",
            "placeholder": "​",
            "style": "IPY_MODEL_92123c7f34cc4e088ad935b23b968087",
            "value": " 2/2 [00:04&lt;00:00,  1.87s/it]"
          }
        },
        "6e9bdfba1d994ae592c755e0c50ae5e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36c923139be14a569782aac549f46ff3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dba9289556404d17addeedca243f219f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6d858af6fe7048548211a35c186d7681": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "118d9697c88a43c28bfb10c58b1f0508": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ffcc8e2cc5fa4aafa12bb1847ed34bfe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92123c7f34cc4e088ad935b23b968087": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-FyfWJ5uHbcZ",
        "outputId": "85cd3f5f-7960-4e48-cf68-671237f04778"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping torchvision as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping torchaudio as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping triton as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping bitsandbytes as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping transformers as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping accelerate as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping peft as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mLooking in indexes: https://download.pytorch.org/whl/cu121\n",
            "Requirement already satisfied: torch==2.4.1 in /usr/local/lib/python3.12/dist-packages (2.4.1+cu121)\n",
            "Collecting torchvision==0.19.1\n",
            "  Using cached https://download.pytorch.org/whl/cu121/torchvision-0.19.1%2Bcu121-cp312-cp312-linux_x86_64.whl (7.1 MB)\n",
            "Collecting torchaudio==2.4.1\n",
            "  Using cached https://download.pytorch.org/whl/cu121/torchaudio-2.4.1%2Bcu121-cp312-cp312-linux_x86_64.whl (3.4 MB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch==2.4.1) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.4.1) (4.15.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from torch==2.4.1) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch==2.4.1) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch==2.4.1) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch==2.4.1) (2024.3.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch==2.4.1) (75.2.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch==2.4.1) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch==2.4.1) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch==2.4.1) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.12/dist-packages (from torch==2.4.1) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.4.1) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.12/dist-packages (from torch==2.4.1) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.12/dist-packages (from torch==2.4.1) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.12/dist-packages (from torch==2.4.1) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.12/dist-packages (from torch==2.4.1) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.12/dist-packages (from torch==2.4.1) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch==2.4.1) (12.1.105)\n",
            "Collecting triton==3.0.0 (from torch==2.4.1)\n",
            "  Using cached https://download.pytorch.org/whl/triton-3.0.0-1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.5 MB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision==0.19.1) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision==0.19.1) (11.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.12/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.4.1) (12.6.85)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch==2.4.1) (3.0.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->torch==2.4.1) (1.3.0)\n",
            "Installing collected packages: triton, torchvision, torchaudio\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "sentence-transformers 5.1.1 requires transformers<5.0.0,>=4.41.0, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed torchaudio-2.4.1+cu121 torchvision-0.19.1+cu121 triton-3.0.0\n",
            "Collecting transformers==4.44.2\n",
            "  Using cached transformers-4.44.2-py3-none-any.whl.metadata (43 kB)\n",
            "Requirement already satisfied: sentence-transformers==5.1.1 in /usr/local/lib/python3.12/dist-packages (5.1.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers==4.44.2) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.12/dist-packages (from transformers==4.44.2) (0.35.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers==4.44.2) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers==4.44.2) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers==4.44.2) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers==4.44.2) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers==4.44.2) (2.32.4)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.12/dist-packages (from transformers==4.44.2) (0.6.2)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.12/dist-packages (from transformers==4.44.2) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers==4.44.2) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers==5.1.1) (2.4.1+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers==5.1.1) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers==5.1.1) (1.16.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from sentence-transformers==5.1.1) (11.3.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers==5.1.1) (4.15.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.44.2) (2024.3.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.44.2) (1.1.10)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers==5.1.1) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers==5.1.1) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers==5.1.1) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers==5.1.1) (75.2.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers==5.1.1) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers==5.1.1) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers==5.1.1) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers==5.1.1) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers==5.1.1) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers==5.1.1) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers==5.1.1) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers==5.1.1) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers==5.1.1) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers==5.1.1) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers==5.1.1) (12.1.105)\n",
            "Requirement already satisfied: triton==3.0.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers==5.1.1) (3.0.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.12/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence-transformers==5.1.1) (12.6.85)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.44.2) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.44.2) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.44.2) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.44.2) (2025.10.5)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers==5.1.1) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers==5.1.1) (3.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers==5.1.1) (3.0.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->torch>=1.11.0->sentence-transformers==5.1.1) (1.3.0)\n",
            "Using cached transformers-4.44.2-py3-none-any.whl (9.5 MB)\n",
            "Installing collected packages: transformers\n",
            "Successfully installed transformers-4.44.2\n"
          ]
        }
      ],
      "source": [
        "# CLEAN\n",
        "!pip uninstall -y torchvision torchaudio triton bitsandbytes transformers accelerate peft\n",
        "\n",
        "# TORCH FAMILY (CUDA 12.1 band)\n",
        "!pip install --index-url https://download.pytorch.org/whl/cu121 \\\n",
        "  \"torch==2.4.1\" \"torchvision==0.19.1\" \"torchaudio==2.4.1\"\n",
        "\n",
        "!pip install \"transformers==4.44.2\" \"sentence-transformers==5.1.1\"\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install \\\n",
        "  \"triton==3.0.0\" \\\n",
        "  \"bitsandbytes==0.44.1\" \\\n",
        "  \"transformers==4.44.2\" \\\n",
        "  \"accelerate==0.34.2\" \\\n",
        "  \"peft==0.13.0\" \\\n",
        "  \"datasets==2.19.1\" \\\n",
        "  sentencepiece safetensors huggingface_hub hf-transfer codecarbon \\\n",
        "  \"sentence-transformers==5.1.1\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R623xjLHfSBR",
        "outputId": "ba96140a-d0fa-4c37-d792-cb083352311f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: triton==3.0.0 in /usr/local/lib/python3.12/dist-packages (3.0.0)\n",
            "Collecting bitsandbytes==0.44.1\n",
            "  Using cached bitsandbytes-0.44.1-py3-none-manylinux_2_24_x86_64.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: transformers==4.44.2 in /usr/local/lib/python3.12/dist-packages (4.44.2)\n",
            "Collecting accelerate==0.34.2\n",
            "  Using cached accelerate-0.34.2-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting peft==0.13.0\n",
            "  Using cached peft-0.13.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: datasets==2.19.1 in /usr/local/lib/python3.12/dist-packages (2.19.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (0.2.1)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.12/dist-packages (0.6.2)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.12/dist-packages (0.35.3)\n",
            "Requirement already satisfied: hf-transfer in /usr/local/lib/python3.12/dist-packages (0.1.9)\n",
            "Requirement already satisfied: codecarbon in /usr/local/lib/python3.12/dist-packages (3.0.7)\n",
            "Requirement already satisfied: sentence-transformers==5.1.1 in /usr/local/lib/python3.12/dist-packages (5.1.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from triton==3.0.0) (3.20.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from bitsandbytes==0.44.1) (2.4.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from bitsandbytes==0.44.1) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers==4.44.2) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers==4.44.2) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers==4.44.2) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers==4.44.2) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.12/dist-packages (from transformers==4.44.2) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers==4.44.2) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate==0.34.2) (7.1.0)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets==2.19.1) (18.1.0)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.12/dist-packages (from datasets==2.19.1) (0.7)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets==2.19.1) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets==2.19.1) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets==2.19.1) (3.6.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.12/dist-packages (from datasets==2.19.1) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.3.1,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2024.3.1,>=2023.1.0->datasets==2.19.1) (2024.3.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from datasets==2.19.1) (3.13.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers==5.1.1) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers==5.1.1) (1.16.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from sentence-transformers==5.1.1) (11.3.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers==5.1.1) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (1.1.10)\n",
            "Requirement already satisfied: arrow in /usr/local/lib/python3.12/dist-packages (from codecarbon) (1.3.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from codecarbon) (8.3.0)\n",
            "Requirement already satisfied: fief-client[cli] in /usr/local/lib/python3.12/dist-packages (from codecarbon) (0.20.0)\n",
            "Requirement already satisfied: prometheus_client in /usr/local/lib/python3.12/dist-packages (from codecarbon) (0.23.1)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.12/dist-packages (from codecarbon) (9.0.0)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.12/dist-packages (from codecarbon) (2.11.10)\n",
            "Requirement already satisfied: nvidia-ml-py in /usr/local/lib/python3.12/dist-packages (from codecarbon) (12.575.51)\n",
            "Requirement already satisfied: rapidfuzz in /usr/local/lib/python3.12/dist-packages (from codecarbon) (3.14.1)\n",
            "Requirement already satisfied: questionary in /usr/local/lib/python3.12/dist-packages (from codecarbon) (2.1.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from codecarbon) (13.9.4)\n",
            "Requirement already satisfied: typer in /usr/local/lib/python3.12/dist-packages (from codecarbon) (0.19.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.19.1) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.19.1) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.19.1) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.19.1) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.19.1) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.19.1) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.19.1) (1.22.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.44.2) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.44.2) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.44.2) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.44.2) (2025.10.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from torch->bitsandbytes==0.44.1) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch->bitsandbytes==0.44.1) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->bitsandbytes==0.44.1) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->bitsandbytes==0.44.1) (75.2.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch->bitsandbytes==0.44.1) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch->bitsandbytes==0.44.1) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch->bitsandbytes==0.44.1) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.12/dist-packages (from torch->bitsandbytes==0.44.1) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.12/dist-packages (from torch->bitsandbytes==0.44.1) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.12/dist-packages (from torch->bitsandbytes==0.44.1) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.12/dist-packages (from torch->bitsandbytes==0.44.1) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.12/dist-packages (from torch->bitsandbytes==0.44.1) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.12/dist-packages (from torch->bitsandbytes==0.44.1) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.12/dist-packages (from torch->bitsandbytes==0.44.1) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch->bitsandbytes==0.44.1) (12.1.105)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.12/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->bitsandbytes==0.44.1) (12.6.85)\n",
            "Requirement already satisfied: python-dateutil>=2.7.0 in /usr/local/lib/python3.12/dist-packages (from arrow->codecarbon) (2.9.0.post0)\n",
            "Requirement already satisfied: types-python-dateutil>=2.8.10 in /usr/local/lib/python3.12/dist-packages (from arrow->codecarbon) (2.9.0.20251008)\n",
            "Requirement already satisfied: httpx<0.28.0,>=0.21.3 in /usr/local/lib/python3.12/dist-packages (from fief-client[cli]->codecarbon) (0.27.2)\n",
            "Requirement already satisfied: jwcrypto<2.0.0,>=1.4 in /usr/local/lib/python3.12/dist-packages (from fief-client[cli]->codecarbon) (1.5.6)\n",
            "Requirement already satisfied: yaspin in /usr/local/lib/python3.12/dist-packages (from fief-client[cli]->codecarbon) (3.3.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets==2.19.1) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets==2.19.1) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic->codecarbon) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic->codecarbon) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic->codecarbon) (0.4.2)\n",
            "Requirement already satisfied: prompt_toolkit<4.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from questionary->codecarbon) (3.0.52)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->codecarbon) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->codecarbon) (2.19.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers==5.1.1) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers==5.1.1) (3.6.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer->codecarbon) (1.5.4)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<0.28.0,>=0.21.3->fief-client[cli]->codecarbon) (4.11.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<0.28.0,>=0.21.3->fief-client[cli]->codecarbon) (1.0.9)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from httpx<0.28.0,>=0.21.3->fief-client[cli]->codecarbon) (1.3.1)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<0.28.0,>=0.21.3->fief-client[cli]->codecarbon) (0.16.0)\n",
            "Requirement already satisfied: cryptography>=3.4 in /usr/local/lib/python3.12/dist-packages (from jwcrypto<2.0.0,>=1.4->fief-client[cli]->codecarbon) (43.0.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->codecarbon) (0.1.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prompt_toolkit<4.0,>=2.0->questionary->codecarbon) (0.2.14)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7.0->arrow->codecarbon) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->bitsandbytes==0.44.1) (3.0.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->torch->bitsandbytes==0.44.1) (1.3.0)\n",
            "Requirement already satisfied: termcolor<4.0,>=3.1 in /usr/local/lib/python3.12/dist-packages (from yaspin->fief-client[cli]->codecarbon) (3.1.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography>=3.4->jwcrypto<2.0.0,>=1.4->fief-client[cli]->codecarbon) (2.0.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography>=3.4->jwcrypto<2.0.0,>=1.4->fief-client[cli]->codecarbon) (2.23)\n",
            "Using cached bitsandbytes-0.44.1-py3-none-manylinux_2_24_x86_64.whl (122.4 MB)\n",
            "Using cached accelerate-0.34.2-py3-none-any.whl (324 kB)\n",
            "Using cached peft-0.13.0-py3-none-any.whl (322 kB)\n",
            "Installing collected packages: bitsandbytes, accelerate, peft\n",
            "Successfully installed accelerate-0.34.2 bitsandbytes-0.44.1 peft-0.13.0\n",
            "Requirement already satisfied: triton==3.0.0 in /usr/local/lib/python3.12/dist-packages (3.0.0)\n",
            "Requirement already satisfied: bitsandbytes==0.44.1 in /usr/local/lib/python3.12/dist-packages (0.44.1)\n",
            "Requirement already satisfied: transformers==4.44.2 in /usr/local/lib/python3.12/dist-packages (4.44.2)\n",
            "Requirement already satisfied: accelerate==0.34.2 in /usr/local/lib/python3.12/dist-packages (0.34.2)\n",
            "Requirement already satisfied: peft==0.13.0 in /usr/local/lib/python3.12/dist-packages (0.13.0)\n",
            "Requirement already satisfied: datasets==2.19.1 in /usr/local/lib/python3.12/dist-packages (2.19.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (0.2.1)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.12/dist-packages (0.6.2)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.12/dist-packages (0.35.3)\n",
            "Requirement already satisfied: hf-transfer in /usr/local/lib/python3.12/dist-packages (0.1.9)\n",
            "Requirement already satisfied: codecarbon in /usr/local/lib/python3.12/dist-packages (3.0.7)\n",
            "Requirement already satisfied: sentence-transformers==5.1.1 in /usr/local/lib/python3.12/dist-packages (5.1.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from triton==3.0.0) (3.20.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from bitsandbytes==0.44.1) (2.4.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from bitsandbytes==0.44.1) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers==4.44.2) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers==4.44.2) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers==4.44.2) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers==4.44.2) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.12/dist-packages (from transformers==4.44.2) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers==4.44.2) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate==0.34.2) (7.1.0)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets==2.19.1) (18.1.0)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.12/dist-packages (from datasets==2.19.1) (0.7)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets==2.19.1) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets==2.19.1) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets==2.19.1) (3.6.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.12/dist-packages (from datasets==2.19.1) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.3.1,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2024.3.1,>=2023.1.0->datasets==2.19.1) (2024.3.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from datasets==2.19.1) (3.13.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers==5.1.1) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers==5.1.1) (1.16.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from sentence-transformers==5.1.1) (11.3.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers==5.1.1) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (1.1.10)\n",
            "Requirement already satisfied: arrow in /usr/local/lib/python3.12/dist-packages (from codecarbon) (1.3.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from codecarbon) (8.3.0)\n",
            "Requirement already satisfied: fief-client[cli] in /usr/local/lib/python3.12/dist-packages (from codecarbon) (0.20.0)\n",
            "Requirement already satisfied: prometheus_client in /usr/local/lib/python3.12/dist-packages (from codecarbon) (0.23.1)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.12/dist-packages (from codecarbon) (9.0.0)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.12/dist-packages (from codecarbon) (2.11.10)\n",
            "Requirement already satisfied: nvidia-ml-py in /usr/local/lib/python3.12/dist-packages (from codecarbon) (12.575.51)\n",
            "Requirement already satisfied: rapidfuzz in /usr/local/lib/python3.12/dist-packages (from codecarbon) (3.14.1)\n",
            "Requirement already satisfied: questionary in /usr/local/lib/python3.12/dist-packages (from codecarbon) (2.1.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from codecarbon) (13.9.4)\n",
            "Requirement already satisfied: typer in /usr/local/lib/python3.12/dist-packages (from codecarbon) (0.19.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.19.1) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.19.1) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.19.1) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.19.1) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.19.1) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.19.1) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.19.1) (1.22.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.44.2) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.44.2) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.44.2) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.44.2) (2025.10.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from torch->bitsandbytes==0.44.1) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch->bitsandbytes==0.44.1) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->bitsandbytes==0.44.1) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->bitsandbytes==0.44.1) (75.2.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch->bitsandbytes==0.44.1) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch->bitsandbytes==0.44.1) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch->bitsandbytes==0.44.1) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.12/dist-packages (from torch->bitsandbytes==0.44.1) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.12/dist-packages (from torch->bitsandbytes==0.44.1) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.12/dist-packages (from torch->bitsandbytes==0.44.1) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.12/dist-packages (from torch->bitsandbytes==0.44.1) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.12/dist-packages (from torch->bitsandbytes==0.44.1) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.12/dist-packages (from torch->bitsandbytes==0.44.1) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.12/dist-packages (from torch->bitsandbytes==0.44.1) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch->bitsandbytes==0.44.1) (12.1.105)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.12/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->bitsandbytes==0.44.1) (12.6.85)\n",
            "Requirement already satisfied: python-dateutil>=2.7.0 in /usr/local/lib/python3.12/dist-packages (from arrow->codecarbon) (2.9.0.post0)\n",
            "Requirement already satisfied: types-python-dateutil>=2.8.10 in /usr/local/lib/python3.12/dist-packages (from arrow->codecarbon) (2.9.0.20251008)\n",
            "Requirement already satisfied: httpx<0.28.0,>=0.21.3 in /usr/local/lib/python3.12/dist-packages (from fief-client[cli]->codecarbon) (0.27.2)\n",
            "Requirement already satisfied: jwcrypto<2.0.0,>=1.4 in /usr/local/lib/python3.12/dist-packages (from fief-client[cli]->codecarbon) (1.5.6)\n",
            "Requirement already satisfied: yaspin in /usr/local/lib/python3.12/dist-packages (from fief-client[cli]->codecarbon) (3.3.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets==2.19.1) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets==2.19.1) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic->codecarbon) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic->codecarbon) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic->codecarbon) (0.4.2)\n",
            "Requirement already satisfied: prompt_toolkit<4.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from questionary->codecarbon) (3.0.52)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->codecarbon) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->codecarbon) (2.19.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers==5.1.1) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers==5.1.1) (3.6.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer->codecarbon) (1.5.4)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<0.28.0,>=0.21.3->fief-client[cli]->codecarbon) (4.11.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<0.28.0,>=0.21.3->fief-client[cli]->codecarbon) (1.0.9)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from httpx<0.28.0,>=0.21.3->fief-client[cli]->codecarbon) (1.3.1)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<0.28.0,>=0.21.3->fief-client[cli]->codecarbon) (0.16.0)\n",
            "Requirement already satisfied: cryptography>=3.4 in /usr/local/lib/python3.12/dist-packages (from jwcrypto<2.0.0,>=1.4->fief-client[cli]->codecarbon) (43.0.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->codecarbon) (0.1.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prompt_toolkit<4.0,>=2.0->questionary->codecarbon) (0.2.14)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7.0->arrow->codecarbon) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->bitsandbytes==0.44.1) (3.0.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->torch->bitsandbytes==0.44.1) (1.3.0)\n",
            "Requirement already satisfied: termcolor<4.0,>=3.1 in /usr/local/lib/python3.12/dist-packages (from yaspin->fief-client[cli]->codecarbon) (3.1.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography>=3.4->jwcrypto<2.0.0,>=1.4->fief-client[cli]->codecarbon) (2.0.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography>=3.4->jwcrypto<2.0.0,>=1.4->fief-client[cli]->codecarbon) (2.23)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import os\n",
        "from dataclasses import dataclass\n",
        "from pathlib import Path\n",
        "from typing import Dict, List, Optional, Tuple\n",
        "\n",
        "import torch\n",
        "from torch.nn.utils import prune\n",
        "from torch.utils.data import Dataset\n",
        "from transformers import (\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    BitsAndBytesConfig,\n",
        "    PreTrainedModel,\n",
        "    PreTrainedTokenizer,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        ")\n",
        "import csv\n",
        "import time\n",
        "from codecarbon import OfflineEmissionsTracker\n",
        "from google.colab import files\n",
        "import json\n",
        "try:\n",
        "    from google.colab import drive  # noqa: F401\n",
        "    IN_COLAB = True\n",
        "except ImportError:\n",
        "    IN_COLAB = False"
      ],
      "metadata": {
        "id": "NvKea7YQIAcF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Running on {DEVICE} with {torch.cuda.get_device_name(0) if DEVICE.type == 'cuda' else 'CPU-only'}\")\n",
        "\n",
        "BASE_MODEL = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
        "QUAN_OUT_DIR = \"llama3p2-3b-instruct-nf4\"\n",
        "\n",
        "STUDENT_MODEL = \"meta-llama/Llama-3.2-1B\"\n",
        "\n",
        "PROMPTS: Dict[str, str] = {}\n",
        "function_code = \"\"\"\n",
        "from typing import List\n",
        "\n",
        "def below_zero(operations: List[int]) -> bool:\n",
        "    \\\"\\\"\n",
        "    You're given a list of deposit and withdrawal operations\n",
        "    on a bank account that starts with zero balance. Your task is to\n",
        "    detect if at any point the balance of account falls below zero,\n",
        "    and at that point function should return True.\n",
        "    \\\"\\\"\n",
        "    balance = 0\n",
        "    for op in operations:\n",
        "        balance += op\n",
        "        if balance < 0:\n",
        "            return True\n",
        "    return False\n",
        "\"\"\"\n",
        "\n",
        "PROMPTS[\"complete_prompt_text\"] = f\"\"\"\n",
        "Please act as an expert Python software engineer. Given the python function below:\n",
        "{function_code}\n",
        "I would appreciate it if you could generate a complete and professional Google-style docstring.\n",
        "The docstring should not include any extra commentary, strictly limited to include the docstring itself and the original function code.\n",
        "CODE ONLY. Use standard Python indentation. Thank you.\n",
        "Do not add explanations, notes, or text outside of the code.\n",
        "Return only the function code with its docstring, without markdown fences or extra text before or after.\n",
        "\"\"\"\n",
        "\n",
        "PROMPTS[\"concise_prompt_text\"] = f\"\"\"\n",
        "Generate COMPLETE Google-style docstring for the following Python function:\n",
        "{function_code}\n",
        "Output the docstring with the function code. Do not include explanations, notes, or text outside the code.\n",
        "Return only the function code with its docstring, without extra text.\n",
        "\"\"\"\n",
        "\n",
        "PROMPTS[\"ultra_concise_prompt_text\"] = f\"\"\"Add Google-style docstring to function:\n",
        "{function_code}\n",
        "Output code only, no text.\"\"\"\n",
        "\n",
        "def ensure_tokenizer_padding(tokenizer: PreTrainedTokenizer, model: Optional[PreTrainedModel] = None):\n",
        "    if tokenizer.pad_token is None:\n",
        "        tokenizer.add_special_tokens({\"pad_token\": tokenizer.eos_token})\n",
        "        if model:\n",
        "            model.resize_token_embeddings(len(tokenizer))\n",
        "    tokenizer.padding_side = \"right\"\n",
        "\n",
        "def build_prompt(record: Dict[str, str]) -> Tuple[str, str]:\n",
        "    instr = (record.get(\"instruction\") or \"\").strip()\n",
        "    user_input = (record.get(\"input\") or \"\").strip()\n",
        "    output = (record.get(\"output\") or record.get(\"response\") or record.get(\"answer\") or \"\").strip()\n",
        "    prompt = \"### Instruction:\\n\" + instr\n",
        "    if user_input:\n",
        "        prompt += \"\\n\\n### Input:\\n\" + user_input\n",
        "    prompt += \"\\n\\n### Response:\\n\"\n",
        "    return prompt, output\n",
        "\n",
        "class InstructionDataset(Dataset):\n",
        "    def __init__(self, rows: List[Dict[str, str]], tokenizer: PreTrainedTokenizer, max_length: int = 2048):\n",
        "        self.rows = rows\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.rows)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        prompt, response = build_prompt(self.rows[idx])\n",
        "        prompt_ids = self.tokenizer(prompt, add_special_tokens=False)[\"input_ids\"]\n",
        "        response_ids = self.tokenizer(response + self.tokenizer.eos_token, add_special_tokens=False)[\"input_ids\"]\n",
        "        input_ids = (prompt_ids + response_ids)[: self.max_length]\n",
        "        attention_mask = [1] * len(input_ids)\n",
        "        labels = ([-100] * len(prompt_ids) + response_ids)[: len(input_ids)]\n",
        "        if len(labels) < len(input_ids):\n",
        "            labels += [-100] * (len(input_ids) - len(labels))\n",
        "        return {\n",
        "            \"input_ids\": input_ids,\n",
        "            \"attention_mask\": attention_mask,\n",
        "            \"labels\": labels,\n",
        "        }\n",
        "\n",
        "@dataclass\n",
        "class CausalDataCollator:\n",
        "    tokenizer: PreTrainedTokenizer\n",
        "\n",
        "    def __call__(self, features: List[Dict[str, List[int]]]) -> Dict[str, torch.Tensor]:\n",
        "        batch = self.tokenizer.pad(features, padding=True, return_tensors=\"pt\")\n",
        "        labels = batch[\"labels\"]\n",
        "        labels[labels == self.tokenizer.pad_token_id] = -100\n",
        "        batch[\"labels\"] = labels\n",
        "        return batch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ezkisOs0IOSc",
        "outputId": "8aa8449e-e294-4c88-ecd3-ca2078b168b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on cuda with NVIDIA A100-SXM4-80GB\n",
            "Running on cuda with NVIDIA A100-SXM4-80GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Quantize LLaMA 3.1 8B to 4-bit NF4\n"
      ],
      "metadata": {
        "id": "C_DIsMcyIRC_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_use_double_quant=False,\n",
        "    # On A100s, BF16 is stable; keep FP16 if you prefer or if BF16 unsupported\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16 if torch.cuda.is_available() and torch.cuda.is_bf16_supported() else torch.float16,\n",
        ")\n",
        "\n",
        "# Load tokenizer + 4-bit model\n",
        "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL, use_fast=False)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    BASE_MODEL,\n",
        "    quantization_config=bnb_config,\n",
        "    device_map=\"auto\",\n",
        "    trust_remote_code=False,  # not needed for Llama\n",
        ")\n",
        "\n",
        "# Ensure a pad token for causal LM\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "    model.config.pad_token_id = tokenizer.eos_token_id\n",
        "\n",
        "# Save quantized weights + tokenizer\n",
        "tokenizer.save_pretrained(QUAN_OUT_DIR)\n",
        "model.save_pretrained(QUAN_OUT_DIR, safe_serialization=True)\n",
        "print(f\"Saved 4-bit NF4 weights to {QUAN_OUT_DIR}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117,
          "referenced_widgets": [
            "ed6dda0b678747a6a1b33ee3abbc1b98",
            "ec9cdc327eab4ed3b19f3b758d4e2ffb",
            "2e2027e72a99477bada4d7ee7f72f999",
            "1fa9b0b2a7834dc9bf345bc853213890",
            "e1cf4593ccee42c498d80580810b57c1",
            "2a2bf5253ccf4a44a023453ee92f010a",
            "e0c16f471e914e40bc0c65c82dc6700e",
            "462f95f703504a6aa8bf49e5c4fc54c4",
            "e1cf11c9b445493aa6e6b2d782098f02",
            "ca4b0b6112eb4354bbbd9afb1e32f96c",
            "baf838dbddc14c5983a86bff5660f36d",
            "1fbc2db41ea04e5b95e310366fa495b9",
            "60b862d2f0104ea289bec0e4c53ade21",
            "5b2755b00e1242848b9edff6192a0fde",
            "3560534a24ac489aab2bd53fefacf93d",
            "7a194800c02641bd96c73e3e75dfef17",
            "1a82ca4f62a6496999d54348f7ce4654",
            "9ee1956ec95141fe880978d6ae841b9b",
            "2b93df45bc474295b5be6cee43d2ba0d",
            "6b9d7d9a186e452799cbdc32a07174e9",
            "3d66dcaf6aef4efe8691f9bc47e31cfa",
            "3a0a59395c084a7fbfb8bca516e1ddc0"
          ]
        },
        "id": "LtEDKI0yIUUj",
        "outputId": "e3257e10-4525-4033-8e35-e9873e9a7dab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ed6dda0b678747a6a1b33ee3abbc1b98"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved 4-bit NF4 weights to llama3p2-3b-instruct-nf4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1fbc2db41ea04e5b95e310366fa495b9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved 4-bit NF4 weights to llama3p2-3b-instruct-nf4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_docstring_quantization(model_path: str, prompt_key: str = \"complete_prompt_text\", max_new_tokens: int = 256):\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_path, use_fast=False)\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        model_path,\n",
        "        device_map=\"auto\",\n",
        "        torch_dtype=torch.float16,\n",
        "        trust_remote_code=True,\n",
        "    )\n",
        "    prompt = PROMPTS[prompt_key]\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
        "    input_len = inputs[\"input_ids\"].shape[1]\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            **inputs,\n",
        "            do_sample=True,\n",
        "            max_new_tokens=max_new_tokens,\n",
        "            eos_token_id=tokenizer.eos_token_id,\n",
        "            pad_token_id=tokenizer.pad_token_id,\n",
        "        )\n",
        "    gen_ids = outputs[0][input_len:]\n",
        "    text = tokenizer.decode(gen_ids, skip_special_tokens=True).strip()\n",
        "    print(text)\n",
        "\n",
        "generate_docstring_quantization(\"llama3p2-3b-instruct-nf4\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fl_TDTvFIbI9",
        "outputId": "e47bd6ac-55b9-41b0-eed9-25305f804344"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/generation/configuration_utils.py:572: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "def below_zero(operations: List[int]) -> bool:\n",
            "    \"\"\"\n",
            "    Detects if at any point the balance of account falls below zero.\n",
            "\n",
            "    Args:\n",
            "        operations (List[int]): A list of deposit and withdrawal operations\n",
            "            on a bank account that starts with zero balance.\n",
            "\n",
            "    Returns:\n",
            "        bool: True if the balance falls below zero at any point, False otherwise.\n",
            "    \"\"\"\n",
            "    balance = 0\n",
            "    for op in operations:\n",
            "        balance += op\n",
            "        if balance < 0:\n",
            "            return True\n",
            "    return False\n",
            "```\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/generation/configuration_utils.py:572: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "def below_zero(operations: List[int]) -> bool:\n",
            "    \"\"\"\n",
            "    Detects if at any point the balance of account falls below zero.\n",
            "\n",
            "    Args:\n",
            "        operations (List[int]): A list of deposit and withdrawal operations\n",
            "            on a bank account that starts with zero balance.\n",
            "\n",
            "    Returns:\n",
            "        bool: True if the balance falls below zero at any point, False otherwise.\n",
            "    \"\"\"\n",
            "    balance = 0\n",
            "    for op in operations:\n",
            "        balance += op\n",
            "        if balance < 0:\n",
            "            return True\n",
            "    return False\n",
            "```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Upload CSV results and build a fine-tuning corpus\n"
      ],
      "metadata": {
        "id": "CNKIpyfLIihz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "print(\"Upload `green_prompt_results_three_models.csv`\")\n",
        "uploaded = files.upload()\n",
        "dataset_rows: List[Dict[str, str]] = []\n",
        "\n",
        "csv_path = next(iter(uploaded.keys()))\n",
        "with open(csv_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    reader = csv.DictReader(f)\n",
        "    for row in reader:\n",
        "        if row[\"Model\"] == \"llama3.1:8b-instruct\" and row[\"Quantization\"] == \"fp16\":\n",
        "            prompt_name = row[\"Prompt\"]\n",
        "            prompt_text = PROMPTS.get(prompt_name)\n",
        "            output_text = row[\"Output\"]\n",
        "            if prompt_text and output_text:\n",
        "                dataset_rows.append(\n",
        "                    {\n",
        "                        \"instruction\": prompt_text,\n",
        "                        \"input\": \"\",\n",
        "                        \"output\": output_text.strip(),\n",
        "                        \"meta\": {\n",
        "                            \"epoch\": row[\"Epoch\"],\n",
        "                            \"prompt\": prompt_name,\n",
        "                            \"accuracy\": row[\"Accuracy\"],\n",
        "                        },\n",
        "                    }\n",
        "                )\n",
        "\n",
        "print(f\"Usable rows: {len(dataset_rows)}\")\n",
        "\n",
        "dataset_path = Path(\"llama3_fp16_docstrings.jsonl\")\n",
        "dataset_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "with dataset_path.open(\"w\", encoding=\"utf-8\") as handle:\n",
        "    for row in dataset_rows:\n",
        "        handle.write(json.dumps(row, ensure_ascii=False) + \"\\n\")\n",
        "print(\"Saved dataset to\", dataset_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 523
        },
        "id": "KmYEPgzfIjnG",
        "outputId": "6ea14198-078d-4f18-b2ed-aa1b7dfe279b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Upload `green_prompt_results_three_models.csv`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-3c512a94-d96c-441c-9c8d-ad27fe3e103d\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-3c512a94-d96c-441c-9c8d-ad27fe3e103d\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving green_prompt_results_three_models.csv to green_prompt_results_three_models (1).csv\n",
            "Usable rows: 15\n",
            "Saved dataset to llama3_fp16_docstrings.jsonl\n",
            "Upload `green_prompt_results_three_models.csv`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-31255674-72dd-4e20-a2ad-b79889966b5f\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-31255674-72dd-4e20-a2ad-b79889966b5f\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2444990405.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Upload `green_prompt_results_three_models.csv`\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0muploaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdataset_rows\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcsv_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muploaded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mupload\u001b[0;34m(target_dir)\u001b[0m\n\u001b[1;32m     70\u001b[0m   \"\"\"\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m   \u001b[0muploaded_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_upload_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmultiple\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m   \u001b[0;31m# Mapping from original filename to filename as saved locally.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m   \u001b[0mlocal_filenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36m_upload_files\u001b[0;34m(multiple)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m   \u001b[0;31m# First result is always an indication that the file picker has completed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m   result = _output.eval_js(\n\u001b[0m\u001b[1;32m    165\u001b[0m       'google.colab._files._uploadFiles(\"{input_id}\", \"{output_id}\")'.format(\n\u001b[1;32m    166\u001b[0m           \u001b[0minput_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result, timeout_sec)\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     if (\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Prune (40 % sparsity) and run a short recovery fine-tune\n"
      ],
      "metadata": {
        "id": "GjMCpKSVIm5y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def magnitude_prune_inplace_cpu(model: torch.nn.Module, sparsity: float = 0.4):\n",
        "    \"\"\"\n",
        "    Hard-masks weights by magnitude using a global quantile threshold per Linear layer.\n",
        "    Runs entirely on CPU to avoid GPU OOM.\n",
        "    \"\"\"\n",
        "    model_cpu = model.to(\"cpu\")\n",
        "    with torch.no_grad():\n",
        "        for m in model_cpu.modules():\n",
        "            if isinstance(m, torch.nn.Linear) and hasattr(m, \"weight\") and m.weight is not None:\n",
        "                w = m.weight.data  # on CPU\n",
        "                # threshold at given sparsity (e.g., 0.4 → zero-out 40% smallest magnitudes)\n",
        "                thr = torch.quantile(w.abs().float(), sparsity)\n",
        "                mask = (w.abs() >= thr)\n",
        "                w.mul_(mask)  # hard mask in place\n",
        "    return model_cpu\n"
      ],
      "metadata": {
        "id": "eTjSAz2lhpHe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, gc, math, torch\n",
        "from pathlib import Path\n",
        "from typing import List, Dict\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments, Trainer\n",
        "\n",
        "# --- A100-friendly runtime knobs ---\n",
        "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"  # reduce fragmentation\n",
        "torch.backends.cuda.matmul.allow_tf32 = True                        # allow TF32 on A100\n",
        "torch.set_float32_matmul_precision(\"high\")\n",
        "\n",
        "def ensure_tokenizer_padding(tokenizer, model):\n",
        "    # Safe pad-token setup for causal LMs\n",
        "    if tokenizer.pad_token is None:\n",
        "        tokenizer.pad_token = tokenizer.eos_token\n",
        "        model.config.pad_token_id = tokenizer.eos_token_id\n",
        "\n",
        "def split_records(records: List[Dict[str, str]], eval_ratio: float = 0.1):\n",
        "    if eval_ratio <= 0 or len(records) < 2:\n",
        "        return records, []\n",
        "    eval_size = max(1, int(math.ceil(len(records) * eval_ratio)))\n",
        "    return records[eval_size:], records[:eval_size]\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "import torch\n",
        "\n",
        "def magnitude_prune_inplace_cpu(model: torch.nn.Module, sparsity: float = 0.4, show_stats: bool = True):\n",
        "    \"\"\"\n",
        "    Unstructured magnitude pruning per Linear layer on CPU with a tqdm progress bar.\n",
        "    Uses k-th smallest magnitude threshold (k = floor(sparsity * N)) per layer\n",
        "    to avoid torch.quantile size limits.\n",
        "    \"\"\"\n",
        "    # Collect layers first so tqdm knows the total\n",
        "    linear_layers = []\n",
        "    for m in model.modules():\n",
        "        if isinstance(m, torch.nn.Linear) and getattr(m, \"weight\", None) is not None:\n",
        "            linear_layers.append(m)\n",
        "\n",
        "    total = len(linear_layers)\n",
        "    if total == 0:\n",
        "        print(\"No torch.nn.Linear layers found to prune.\")\n",
        "        return model\n",
        "\n",
        "    model = model.to(\"cpu\")\n",
        "    zeroed_params = 0\n",
        "    total_params = 0\n",
        "\n",
        "    with torch.no_grad(), tqdm(total=total, desc=f\"CPU pruning @ {int(sparsity*100)}% sparsity\", leave=True) as pbar:\n",
        "        for idx, m in enumerate(linear_layers, 1):\n",
        "            w = m.weight.data  # CPU tensor\n",
        "            N = w.numel()\n",
        "            total_params += N\n",
        "            if N == 0 or sparsity <= 0.0:\n",
        "                pbar.update(1)\n",
        "                continue\n",
        "\n",
        "            k = int(sparsity * N)\n",
        "            if k <= 0:\n",
        "                pbar.update(1)\n",
        "                continue\n",
        "            if k >= N:\n",
        "                w.zero_()\n",
        "                zeroed_params += N\n",
        "                pbar.set_postfix_str(f\"layer {idx}/{total} | zeroed 100%\")\n",
        "                pbar.update(1)\n",
        "                continue\n",
        "\n",
        "            flat = w.abs().float().view(-1)\n",
        "            try:\n",
        "                thr = torch.kthvalue(flat, k).values\n",
        "            except RuntimeError:\n",
        "                # Fallback sampling for extremely large tensors\n",
        "                step = max(1, N // 5_000_000)  # ~<=5M elems\n",
        "                sample = flat[::step]\n",
        "                est_k = max(1, int(len(sample) * sparsity))\n",
        "                thr = torch.kthvalue(sample, est_k).values\n",
        "\n",
        "            mask = (w.abs() >= thr)\n",
        "            # Count zeros after masking for stats (cheap on CPU)\n",
        "            zeroed_params += (N - int(mask.sum().item()))\n",
        "            w.mul_(mask)  # hard-mask in place\n",
        "\n",
        "            kept_pct = (mask.sum().item() / N) * 100.0\n",
        "            pbar.set_postfix_str(f\"layer {idx}/{total} | kept {kept_pct:.1f}%\")\n",
        "            pbar.update(1)\n",
        "\n",
        "    if show_stats and total_params > 0:\n",
        "        overall_zero = 100.0 * zeroed_params / total_params\n",
        "        print(f\"[Prune] Overall zeroed: {overall_zero:.2f}% ({zeroed_params:,}/{total_params:,})\")\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "def prune_and_ft(\n",
        "    sparsity: float = 0.4,          # 0.3–0.5 recommended\n",
        "    max_length: int = 2048,\n",
        "    epochs: float = 0.5,\n",
        "    lr: float = 2e-5,\n",
        "    grad_accum: int = 4,\n",
        "    per_device_bs: int = 1,\n",
        "    eval_ratio: float = 0.2,\n",
        "    logging_steps: int = 5,\n",
        "    output_dir: str = \"llama3p2-3b-pruned-ft\",\n",
        "):\n",
        "    # ---- memory clean ---\n",
        "    gc.collect()\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    # ---- load on CPU (fp32) ---\n",
        "    tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL, use_fast=False)\n",
        "    base_model = AutoModelForCausalLM.from_pretrained(\n",
        "        BASE_MODEL,\n",
        "        device_map=None,             # stay on CPU for pruning\n",
        "        torch_dtype=torch.float32,   # prune in fp32 on CPU\n",
        "        low_cpu_mem_usage=True,\n",
        "        trust_remote_code=True,\n",
        "    )\n",
        "    ensure_tokenizer_padding(tokenizer, base_model)\n",
        "\n",
        "    # ---- prune on CPU  ---\n",
        "    print(f\"Pruning Linear layers on CPU at {int(sparsity*100)}% sparsity …\")\n",
        "    base_model = magnitude_prune_inplace_cpu(base_model, sparsity=sparsity)\n",
        "\n",
        "    # ---- move to A100 in BF16 ---\n",
        "    use_bf16 = torch.cuda.is_available() and torch.cuda.is_bf16_supported()\n",
        "    if torch.cuda.is_available():\n",
        "        device = torch.device(\"cuda\")\n",
        "        dtype  = torch.bfloat16 if use_bf16 else torch.float32\n",
        "        base_model = base_model.to(device=device, dtype=dtype)\n",
        "    else:\n",
        "        device = torch.device(\"cpu\")\n",
        "\n",
        "    # ---- data ---\n",
        "    train_rows, eval_rows = split_records(dataset_rows, eval_ratio)\n",
        "    train_dataset = InstructionDataset(train_rows, tokenizer, max_length)\n",
        "    eval_dataset  = InstructionDataset(eval_rows,  tokenizer, max_length) if eval_rows else None\n",
        "    collator = CausalDataCollator(tokenizer)\n",
        "\n",
        "    # ---- training args  ---\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=output_dir,\n",
        "        num_train_epochs=epochs,\n",
        "        per_device_train_batch_size=per_device_bs,\n",
        "        gradient_accumulation_steps=grad_accum,\n",
        "        learning_rate=lr,\n",
        "        weight_decay=0.0,\n",
        "        warmup_ratio=0.03,\n",
        "        logging_strategy=\"steps\",\n",
        "        logging_steps=logging_steps,\n",
        "        save_strategy=\"no\",\n",
        "        report_to=\"none\",\n",
        "        evaluation_strategy=\"steps\" if eval_dataset is not None else \"no\",\n",
        "        eval_steps=logging_steps if eval_dataset is not None else None,\n",
        "        fp16=False,                 # avoid GradScaler on FP16 grads\n",
        "        bf16=use_bf16,             # True on A100/AMPERE+\n",
        "        dataloader_pin_memory=True,\n",
        "    )\n",
        "\n",
        "    # keep memory lower\n",
        "    base_model.gradient_checkpointing_enable()\n",
        "    base_model.config.use_cache = False\n",
        "\n",
        "    trainer = Trainer(\n",
        "        model=base_model,\n",
        "        tokenizer=tokenizer,\n",
        "        args=training_args,\n",
        "        train_dataset=train_dataset,\n",
        "        eval_dataset=eval_dataset,\n",
        "        data_collator=collator,\n",
        "    )\n",
        "\n",
        "    trainer.train()\n",
        "\n",
        "    # ---- save ---\n",
        "    Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
        "    tokenizer.save_pretrained(output_dir)\n",
        "    base_model = base_model.to(\"cpu\")\n",
        "    base_model.save_pretrained(output_dir, safe_serialization=True)\n",
        "    print(f\"Saved pruned + fine-tuned weights to {output_dir}\")\n",
        "\n",
        "\n",
        "prune_and_ft(sparsity=0.4)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305,
          "referenced_widgets": [
            "6e16e765f0e64926aac95c9db6e024e0",
            "12d3c50d2b1d49a386ad7e44edd71482",
            "597b33f5fe10483492660aa4f5979f85",
            "ff96549691b847f4b342c4e75fc46735",
            "88232c970aaa45c8b94fde572a846c4c",
            "9bf661dda46b443ca51133fd9fa97922",
            "a502c2d1e0974c7581a35e9640f36c12",
            "19bcea2ac950488a8c16b797b85bc02d",
            "a7d4fc7c6d4c475a8a393d9c4bda1d62",
            "238b0cf8ed90456cb54063195c86e6d8",
            "cc24fb6f50ac42149de7574f590a381a",
            "60411189569545cd884e27482fcb89b7",
            "e58392abbf2548b4b575e747e95389e2",
            "e67034b0ab9f42949a96c0ddedfaf126",
            "4f313b556af44b49a328ca6c470e011e",
            "2adaa3031ce94ec696c5ad717d5ca0cc",
            "4a8dea670aa042c18ec8634f3aadc784",
            "a9088a06ad6746e0b5327e17218e3037",
            "368778563a984d3daa2693f0e39594e2",
            "16506219974c42ddb3cfcb7eaba4276f",
            "79146d6ce63447c393f9972e03cf3ea9",
            "8050ce0c8ce74d639840b503d273f2ee"
          ]
        },
        "id": "EClb7RJSI5Sk",
        "outputId": "a8f5d9f3-b38b-4bd4-b084-e5087b3d1b47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6e16e765f0e64926aac95c9db6e024e0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pruning Linear layers on CPU at 40% sparsity …\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "CPU pruning @ 40% sparsity:   0%|          | 0/197 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "60411189569545cd884e27482fcb89b7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Prune] Overall zeroed: 39.89% (1,281,644,973/3,212,574,720)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "You're using a PreTrainedTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2/2 00:00, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved pruned + fine-tuned weights to llama3p1-8b-pruned-ft\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Docstring generator for the pruned model\n"
      ],
      "metadata": {
        "id": "vAW7RhgiI_a3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_docstring_prune(model_dir: str, prompt_key: str = \"complete_prompt_text\", max_new_tokens: int = 256):\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_dir, use_fast=False)\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        model_dir,\n",
        "        torch_dtype=torch.float16,\n",
        "        device_map=\"auto\",\n",
        "        trust_remote_code=True,\n",
        "    )\n",
        "    ensure_tokenizer_padding(tokenizer, model)\n",
        "    prompt = PROMPTS[prompt_key]\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
        "    input_len = inputs[\"input_ids\"].shape[1]\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            **inputs,\n",
        "            do_sample=True,\n",
        "            max_new_tokens=max_new_tokens,\n",
        "            eos_token_id=tokenizer.eos_token_id,\n",
        "            pad_token_id=tokenizer.pad_token_id,\n",
        "        )\n",
        "    gen_ids = outputs[0][input_len:]\n",
        "    text = tokenizer.decode(gen_ids, skip_special_tokens=True).strip()\n",
        "    print(text)\n",
        "\n",
        "generate_docstring_prune(\"llama3p2-3b-pruned-ft\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 909,
          "referenced_widgets": [
            "ba906055b6ed46009fe3041771dc4082",
            "538d0737d52f49e080663f5a86c8a51a",
            "ebdde29e7b7d4ea89497dbfd3a21dc9d",
            "a452e602ccc3406aa24bbb765a138b09",
            "b0161f94db37448bb88694b2e8184f93",
            "53bf9b7b6ee74374b5d5384754b1912c",
            "d8226b7023b249b18fae08b9d104fb38",
            "b758e222d54042278fa635070118461d",
            "d933bd782fd14567a329418f0cad4ba4",
            "ee8c631cd89549a180f34f5f5062f57a",
            "1e26e82fd54343339e1aa9073b7576c4"
          ]
        },
        "id": "_J94-uUHJAj3",
        "outputId": "797eea89-ac2e-42aa-bef3-f501b2692974"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ba906055b6ed46009fe3041771dc4082"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/generation/configuration_utils.py:572: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "```python\n",
            "from typing import List\n",
            "\n",
            "def below_zero(operations: List[int]) -> bool:\n",
            "    \"\"\"\n",
            "    Detects if at any point the balance of a bank account falls below zero.\n",
            "\n",
            "    Args:\n",
            "        operations (List[int]): A list of integers representing deposit (positive) or withdrawal (negative) amounts.\n",
            "\n",
            "    Returns:\n",
            "        bool: True if the balance falls below zero at any point, False otherwise.\n",
            "    \"\"\"\n",
            "    balance = 0\n",
            "    for op in operations:\n",
            "        balance += op\n",
            "        if balance < 0:\n",
            "            return True\n",
            "    return False\n",
            "```python\n",
            "from typing import List\n",
            "\n",
            "def below_zero(operations: List[int]) -> bool:\n",
            "    \"\"\"\n",
            "    Detects if at any point the balance of a bank account falls below zero.\n",
            "\n",
            "    Args:\n",
            "        operations (List[int]): A list of integers representing deposit (positive) or withdrawal (negative) amounts.\n",
            "\n",
            "    Returns:\n",
            "        bool: True if the balance falls below zero at any point, False otherwise.\n",
            "    \"\"\"\n",
            "    balance = 0\n",
            "    for op in operations:\n",
            "        balance += op\n",
            "        if balance < 0:\n",
            "            return True\n",
            "    return False\n",
            "```python\n",
            "from typing import List\n",
            "\n",
            "def below_zero(operations: List[int]) -> bool:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model_size_gb(model):\n",
        "  torch.save(model.state_dict(), \"temp_model.pt\")\n",
        "  size_mb = os.path.getsize(\"temp_model.pt\") / (1024 * 1024)\n",
        "  os.remove(\"temp_model.pt\")\n",
        "  return size_mb"
      ],
      "metadata": {
        "id": "2iU1M8hELAQR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "RUNS_PER_MODEL = 5\n",
        "PROMPT_KEY = \"complete_prompt_text\"\n",
        "MAX_NEW_TOKENS = 256\n",
        "COUNTRY_CODE = \"USA\"\n",
        "METRICS_PATH = Path(\"docstring_metrics_runs.csv\")\n",
        "\n",
        "NF4_MODEL_DIR   = str(Path(\"./llama3p2-3b-instruct-nf4\").resolve())\n",
        "PRUNE_FT_DIR    = str(Path(\"./llama3p2-3b-pruned-ft\").resolve())\n",
        "\n",
        "try:\n",
        "    torch.backends.cuda.enable_flash_sdp(False)\n",
        "    torch.backends.cuda.enable_mem_efficient_sdp(False)\n",
        "    torch.backends.cuda.enable_math_sdp(True)\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "def _sdp_math_ctx():\n",
        "    try:\n",
        "        return torch.backends.cuda.sdp_kernel(\n",
        "            enable_flash=False, enable_math=True, enable_mem_efficient=False\n",
        "        )\n",
        "    except AttributeError:\n",
        "        # older torch: no-op\n",
        "        from contextlib import contextmanager\n",
        "        @contextmanager\n",
        "        def _noop():\n",
        "            yield\n",
        "        return _noop()\n",
        "def load_pair(model_dir_or_id: str):\n",
        "    tok = AutoTokenizer.from_pretrained(model_dir_or_id, use_fast=False, trust_remote_code=True)\n",
        "    mdl = AutoModelForCausalLM.from_pretrained(\n",
        "        model_dir_or_id,\n",
        "        torch_dtype=torch.float16,\n",
        "        device_map=\"auto\",\n",
        "        trust_remote_code=True,\n",
        "        low_cpu_mem_usage=True,\n",
        "        attn_implementation=\"eager\",   # <-- enable eager attention\n",
        "    )\n",
        "    if tok.pad_token_id is None:\n",
        "        tok.pad_token = tok.eos_token\n",
        "\n",
        "    vocab = mdl.get_input_embeddings().num_embeddings\n",
        "    for tid_name, tid in {\"eos\": tok.eos_token_id, \"pad\": tok.pad_token_id}.items():\n",
        "        assert tid is not None and 0 <= tid < vocab, f\"{tid_name}_token_id out of range\"\n",
        "\n",
        "    mdl.generation_config.eos_token_id = tok.eos_token_id\n",
        "    mdl.generation_config.pad_token_id = tok.pad_token_id\n",
        "    return tok, mdl\n",
        "\n",
        "VARIANTS = [\n",
        "    {\n",
        "        \"key\": \"baseline_fp16\",\n",
        "        \"label\": \"Llama 3.2 3B FP16 (baseline)\",\n",
        "        \"load_fn\": lambda: load_pair(BASE_MODEL),\n",
        "    },\n",
        "    {\n",
        "        \"key\": \"quantized_nf4\",\n",
        "        \"label\": \"Llama 3.2 3B NF4 Quantized (local)\",\n",
        "        \"load_fn\": lambda: load_pair(NF4_MODEL_DIR),\n",
        "    },\n",
        "    {\n",
        "        \"key\": \"pruned_ft\",\n",
        "        \"label\": \"Llama 3.2 3B Pruned + Fine-Tuned (local)\",\n",
        "        \"load_fn\": lambda: load_pair(PRUNE_FT_DIR),\n",
        "    },\n",
        "]\n",
        "\n",
        "records = []\n",
        "\n",
        "for variant in VARIANTS:\n",
        "    print(f\"Measuring {variant['label']}...\")\n",
        "    tokenizer, model = variant[\"load_fn\"]()\n",
        "    ensure_tokenizer_padding(tokenizer, model)\n",
        "    model.eval()\n",
        "    model_size_mb = get_model_size_gb(model)\n",
        "\n",
        "    prompt_text = PROMPTS[PROMPT_KEY]\n",
        "    inputs = tokenizer(prompt_text, return_tensors=\"pt\")\n",
        "    if hasattr(model, \"device\"):\n",
        "        inputs = inputs.to(model.device)\n",
        "    input_length = inputs[\"input_ids\"].shape[1]\n",
        "\n",
        "    for run_idx in range(1, RUNS_PER_MODEL + 1):\n",
        "        # Set random seed for reproducibility\n",
        "        torch.manual_seed(42 + run_idx)\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.manual_seed_all(42 + run_idx)\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.synchronize()\n",
        "        tracker = OfflineEmissionsTracker(\n",
        "            country_iso_code=COUNTRY_CODE,\n",
        "            measure_power_secs=1,\n",
        "            tracking_mode=\"process\",\n",
        "            save_to_file=False,\n",
        "            log_level=\"error\",\n",
        "        )\n",
        "        tracker.start()\n",
        "        start_time = time.perf_counter()\n",
        "\n",
        "        with torch.inference_mode():\n",
        "            outputs = model.generate(\n",
        "                **inputs,\n",
        "                do_sample=True,\n",
        "                max_new_tokens=MAX_NEW_TOKENS,\n",
        "                eos_token_id=tokenizer.eos_token_id,\n",
        "                pad_token_id=tokenizer.pad_token_id,\n",
        "        )\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.synchronize()\n",
        "        latency_s = time.perf_counter() - start_time\n",
        "        co2_kg = tracker.stop() or 0.0\n",
        "\n",
        "        generated_ids = outputs[0][input_length:]\n",
        "        output_text = tokenizer.decode(generated_ids, skip_special_tokens=True).strip()\n",
        "\n",
        "        records.append(\n",
        "            {\n",
        "                \"model_key\": variant[\"key\"],\n",
        "                \"model_label\": variant[\"label\"],\n",
        "                \"run_index\": run_idx,\n",
        "                \"co2_kg\": float(co2_kg),\n",
        "                \"latency_s\": float(latency_s),\n",
        "                \"model_size_mb\": float(model_size_mb),\n",
        "                \"output\": output_text,\n",
        "                \"accuracy\": \"N/A\",\n",
        "            }\n",
        "        )\n",
        "        print(f\"  Run {run_idx}: latency={latency_s:.2f}s | CO2={co2_kg:.6f} kg\")\n",
        "\n",
        "    del model\n",
        "    del tokenizer\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "fieldnames = [\n",
        "    \"model_key\",\n",
        "    \"model_label\",\n",
        "    \"run_index\",\n",
        "    \"co2_kg\",\n",
        "    \"latency_s\",\n",
        "    \"model_size_mb\",\n",
        "    \"output\",\n",
        "    \"accuracy\",\n",
        "]\n",
        "\n",
        "with METRICS_PATH.open(\"w\", newline=\"\", encoding=\"utf-8\") as handle:\n",
        "    writer = csv.DictWriter(handle, fieldnames=fieldnames)\n",
        "    writer.writeheader()\n",
        "    writer.writerows(records)\n",
        "\n",
        "print(f\"Saved metrics to {METRICS_PATH}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466,
          "referenced_widgets": [
            "fc41030e21c7477ab782be6362198446",
            "298522458e7a4990a248ed8bdd1b0c41",
            "84b78169792742d692268084c90fb43b",
            "cb18ecfd1cf04c58addabca7d39f28c4",
            "fa4f9685d814419699b42f81c96407bf",
            "4cc7c681470b4cfdb905e6bb77f90911",
            "5a9dfd686c2147eba80876e52bb680c4",
            "94e2e9702b044bfaabec0a260a97477f",
            "47b7da83d30c45b690548d0d6ede3715",
            "eb63ee87d0e34974b427707ea94fc847",
            "aaf825e156534d96a108073b6d9b47f0",
            "ceb322c9609d4f21b1887976d2984bcc",
            "cc4d447d4db3439f8eb4c0214e22daf2",
            "6a2c27e9191d44bba0e55bff7ae71194",
            "d07f6d79530848f381e4bebee85d9877",
            "6e9bdfba1d994ae592c755e0c50ae5e9",
            "36c923139be14a569782aac549f46ff3",
            "dba9289556404d17addeedca243f219f",
            "6d858af6fe7048548211a35c186d7681",
            "118d9697c88a43c28bfb10c58b1f0508",
            "ffcc8e2cc5fa4aafa12bb1847ed34bfe",
            "92123c7f34cc4e088ad935b23b968087"
          ]
        },
        "id": "17IQIlrvpd63",
        "outputId": "d4305a5a-60ba-4dc5-d46a-d9d655f627bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Measuring Llama 3.2 3B FP16 (baseline)...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fc41030e21c7477ab782be6362198446"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Run 1: latency=5.08s | CO2=0.000071 kg\n",
            "  Run 2: latency=3.78s | CO2=0.000053 kg\n",
            "  Run 3: latency=3.65s | CO2=0.000052 kg\n",
            "  Run 4: latency=8.28s | CO2=0.000117 kg\n",
            "  Run 5: latency=3.70s | CO2=0.000052 kg\n",
            "Measuring Llama 3.2 3B NF4 Quantized (local)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Run 1: latency=6.86s | CO2=0.000086 kg\n",
            "  Run 2: latency=6.81s | CO2=0.000086 kg\n",
            "  Run 3: latency=5.87s | CO2=0.000075 kg\n",
            "  Run 4: latency=6.81s | CO2=0.000087 kg\n",
            "  Run 5: latency=14.66s | CO2=0.000185 kg\n",
            "Measuring Llama 3.2 3B Pruned + Fine-Tuned (local)...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ceb322c9609d4f21b1887976d2984bcc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Run 1: latency=8.69s | CO2=0.000121 kg\n",
            "  Run 2: latency=8.33s | CO2=0.000117 kg\n",
            "  Run 3: latency=8.30s | CO2=0.000117 kg\n",
            "  Run 4: latency=8.25s | CO2=0.000116 kg\n",
            "  Run 5: latency=8.36s | CO2=0.000117 kg\n",
            "Saved metrics to docstring_metrics_runs.csv\n"
          ]
        }
      ]
    }
  ]
}